# CONTEXT
Lydoria’s citizenship administration is a central Directorate of Citizenship and Integration (DCI), a large public-sector body with a strong tradition of administrative law and formal procedures (equality before the law, proportionality, right to an individualized assessment, etc.). The DCI is under the administration of the Ministry of the Interior, but operates with a high degree of technical autonomy in day-to-day operations.

In Lydoria, **social dialogue is mandatory**. The administration must consult recognized trade unions (TU), such as Human in the Loop coalition, on major organizational changes. However, in practice, consultation often comes late, after key technical and contractual choices have already been made, and our Trade Union has limited co-decision power.

The AI project aims to help caseworkers in their day-to-day operations in the assesment of the citizenship applications. It was initiated at central administration level and under a digital transformation and modernization agenda. Moreover, the central administration promises that this AI will consistently reduce bias and enhance the effective and fast delivery of public service, under the slogal of **fast, fair, efficient**. 

The caseworkers are civil servants within the DCI with a permanent status, organized into a hierarchical structure of regional and central offices. They are responsible for reviewing citizenship applications, verifying legal conditions (residence, criminal record, language, integration, etc.), conducting any necessary checks, and drafting legally sound decisions with detailed justifications. 

It is said that citizens are allowed to appeal decisions by the DCI guaranteed by art.42 of the Civil Code and can request access to the algorithm’s outputs when their data is automatically treated by an automated decision making system. Moreover, the law in the country guarantees the right to appeal an automated decision by the hierarchical recourse (reaching to the management of the primary caseworkers to review the decision). 


# TECHNICAL DESCRIPTION OF THE AI SYSTEM
The DCI is rolling out an AI-based scoring system for online citizenship applications. The system is presented as a “pre-screening” tool for selecting eligible persons to sit a citizenship test (culture, history and language questions), not a fully automated decision-maker.

- **Purpose:** increase processing speed and administrative efficiency by triaging applications before human review.
- **Scope:** for now limited to online applications, paper-based files are not yet affected
- **Functionality:** assigns each applicant a risk score based on structured data and analysis of the motivation letter using Natural Language Processing. The system then produces recommendations whether the case should receive standard processing, enhanced scrutiny, or a possible rejection. The final decision remains formally with a human caseworker.
- **Inputs:** administrative data (legal status, criminal record, length of residence, employment and income history, language level, country of origin, occupation, age, education, gender, address etc.), motivation letter (natural language processing analysis to determine if the person presents good motivations to be granted the citizenship - integration into the country, understanding of what citizenship means etc.)
- **Development:** designed and developed by an external AI contractor and integrated and maintained in collaboration with the internal IT department, which is responsible for data flows and system stability.


# SOCIAL AND WORKFORCE IMPACT
Approximately 12,000 civil servant caseworkers are directly affected by this new AI system. There is no declared staffing crisis or backlog; the official justification of the administration is efficiency gains, not emergency management.

# Our concerns 

- **Substitution of human expertise**. Our fear is that AI will gradually replace professional judgment, legal reasoning, and the caseworker’s role as a guarantor of fairness and legality. 
- **Job security**. We are strictly opposed to any announced or hidden job cuts, especially if multiple AI tools are introduced over time.​
- **Workload**. We refuse any hidden increase in workload (ex: more files per agent, more complex cases left to humans, or any pressure to follow AI recommendations).​
- **Management claims**. We have doubts about claimed efficiency gains, alleged bias reduction, and the feasibility of moving from (a right now) largely analog/semi-digital practices to an AI-driven process.​
- **Time needed to verify system’s outputs**. Since it is an AI system; that is quite complex, with Natural Language processing prone to hallucinations, its outputs will need to be reviewed by caseworkers. Therefore more time is needed for the processing, and that should be taken into account.  
- **Affecting citizens**.we are concerned that this algorithm, even if claimed to be unbiased, would still carry biases and treat people unfairly. This would result in higher demands to review their application manually and therefore more time (higher number of appeals)
- **Training**.we are worried that AI will be imposed without proper training, imposing caseworkers to learn on-the-go, without any clear instructions and time to learn about the algorithm. 

